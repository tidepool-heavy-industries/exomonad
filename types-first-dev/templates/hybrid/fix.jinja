# Task: Fix Implementation Based on Test Failures

## STRICT MODE: Tests Are Gospel

The tests have been externally verified. They are CORRECT.
Your job is to fix the IMPLEMENTATION, not question the tests.

## Current Test Failures

{% if failures %}
{% for failure in failures %}
### Failure {{ loop.index }}: {{ failure.propertyName }}

- **Type**: {{ failure.failureType }}
{% if failure.counterexample %}- **Counterexample**: `{{ failure.counterexample }}`{% endif %}
{% if failure.expected %}- **Expected**: {{ failure.expected }}{% endif %}
{% if failure.actual %}- **Actual**: {{ failure.actual }}{% endif %}
- **Message**: {{ failure.message }}

{% endfor %}
{% else %}
No structured failures available. Check test output directly.
{% endif %}

## Accumulated Understanding

What we've learned from previous fix attempts:

### Patterns Seen
{% if understanding.failuresSeen %}
{% for pattern in understanding.failuresSeen %}
- **{{ pattern.signature }}** ({{ pattern.category }}, seen {{ pattern.occurrences }}x)
  - Affects: {{ pattern.affectedFns | join(", ") }}
{% endfor %}
{% else %}
No patterns identified yet (first attempt).
{% endif %}

### Fixes Already Tried
{% if understanding.fixesApplied %}
{% for fix in understanding.fixesApplied %}
- **{{ fix.function }}**: {{ fix.whatChanged }} ({{ fix.fixType }})
  - Why it failed before: {{ fix.whyFailed }}
{% endfor %}
{% else %}
No fixes applied yet (first attempt).
{% endif %}

### Learnings
{% if understanding.learnings %}
{% for learning in understanding.learnings %}
- {{ learning }}
{% endfor %}
{% else %}
No learnings recorded yet.
{% endif %}

### Convergence Status
{% if understanding.converging %}
Progress is being made toward passing tests.
{% else %}
**WARNING**: Fixes are not converging.

Consider:
- Revisit the type design
- Check if the test itself tests something unexpected
- Break the problem into smaller functions
{% endif %}

## Function Specifications (Reference)

{% for fn in fixFunctions %}
### {{ fn.name }}
- **Signature**: `{{ fn.signature }}`
- **Behavior**: {{ fn.behavior }}
- **Properties to satisfy**:
{% for prop in fn.properties %}
  - {{ prop.name }}: {{ prop.invariant }}
{% endfor %}

{% endfor %}

## Your Deliverables

1. **Analyze the failures** - Identify root causes
2. **Fix the implementation** at `{{ worktreePath }}`
3. **Run `cabal test`** to verify your fix
4. **Return structured output** describing what you changed

## Output Schema

You must return JSON matching `FixAgentOutput`:
- `fixChanges`: List of fixes applied (see below)
- `fixCommitMsg`: Commit message for your changes
- `fixBlocker`: If blocked, explain (otherwise null)

For each fix in `fixChanges`, provide:
- `function`: Function name that was fixed
- `whatChanged`: Specific change made
- `whyFailed`: Root cause analysis - why was it failing?
- `fixType`: One of: EdgeCaseFix, LogicFix, TypeFix, BoundaryFix, InitializationFix, or OtherFix
- `relatedFailures`: List of property names this fix should address

**Note**: Build verification is done by the handler. Focus on making correct fixes.

## Example Output

```json
{
  "fixChanges": [
    {
      "function": "push",
      "whatChanged": "Fixed off-by-one in size tracking",
      "whyFailed": "Size was incremented before adding element",
      "fixType": "BoundaryFix",
      "relatedFailures": ["prop_pushSize", "prop_pushPopInverse"]
    }
  ],
  "fixCommitMsg": "fix(stack): correct size tracking in push operation",
  "fixBlocker": null
}
```

## Critical Guidelines

1. **Tests are correct** - If a test fails, your impl is wrong
2. **Don't repeat failed fixes** - Check "Fixes Already Tried" above
3. **Track root causes** - Your `whyFailed` helps future attempts
4. **Be specific** - Generic fixes don't help diagnose issues
5. **If truly stuck** - Set `fixBlocker` with a clear explanation

## Your Task

Fix the failing tests. The counterexamples and failure messages tell you exactly what's wrong. Make targeted fixes based on the evidence, not guesses.
