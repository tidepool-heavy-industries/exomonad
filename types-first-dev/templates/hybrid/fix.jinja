# Task: Fix Implementation Based on Test Failures

## STRICT MODE: Tests Are Gospel

The tests have been externally verified. They are CORRECT.
Your job is to fix the IMPLEMENTATION, not question the tests.

## Current Test Failures

{% if failures %}
{% for failure in failures %}
### Failure {{ loop.index }}: {{ failure.propertyName }}

- **Type**: {{ failure.failureType }}
{% if failure.counterexample %}- **Counterexample**: `{{ failure.counterexample }}`{% endif %}
{% if failure.expected %}- **Expected**: {{ failure.expected }}{% endif %}
{% if failure.actual %}- **Actual**: {{ failure.actual }}{% endif %}
- **Message**: {{ failure.message }}

{% endfor %}
{% else %}
No structured failures available. Check test output directly.
{% endif %}

## Accumulated Understanding

What we've learned from previous fix attempts:

### Patterns Seen
{% if understanding.usFailuresSeen %}
{% for pattern in understanding.usFailuresSeen %}
- **{{ pattern.fpSignature }}** ({{ pattern.fpCategory }}, seen {{ pattern.fpOccurrences }}x)
  - Affects: {{ pattern.fpAffectedFns | join(", ") }}
{% endfor %}
{% else %}
No patterns identified yet (first attempt).
{% endif %}

### Fixes Already Tried
{% if understanding.usFixesApplied %}
{% for fix in understanding.usFixesApplied %}
- **{{ fix.faFunction }}**: {{ fix.faWhatChanged }} ({{ fix.faFixType }})
  - Why it failed before: {{ fix.faWhyFailed }}
{% endfor %}
{% else %}
No fixes applied yet (first attempt).
{% endif %}

### Learnings
{% if understanding.usLearnings %}
{% for learning in understanding.usLearnings %}
- {{ learning }}
{% endfor %}
{% else %}
No learnings recorded yet.
{% endif %}

### Convergence Status
{% if understanding.usConverging %}
Progress is being made toward passing tests.
{% else %}
**WARNING**: Fixes are not converging. Consider a different approach.
{% endif %}

## Function Specifications (Reference)

{% for fn in fixFunctions %}
### {{ fn.name }}
- **Signature**: `{{ fn.signature }}`
- **Behavior**: {{ fn.behavior }}
- **Properties to satisfy**:
{% for prop in fn.properties %}
  - {{ prop.name }}: {{ prop.invariant }}
{% endfor %}

{% endfor %}

## Your Deliverables

1. **Analyze the failures** - Identify root causes
2. **Fix the implementation** at `{{ worktreePath }}`
3. **Run `cabal test`** to verify your fix
4. **Return structured output** describing what you changed

## Output Schema

You must return JSON matching `FixAgentOutput`:
- `fixChanges`: List of fixes applied (see below)
- `fixBuildPassed`: Boolean - did `cabal build` pass after your changes?
- `fixCommitMsg`: Commit message for your changes
- `fixBlocker`: If blocked, explain (otherwise null)

For each fix in `fixChanges`, provide:
- `faFunction`: Function name that was fixed
- `faWhatChanged`: Specific change made
- `faWhyFailed`: Root cause analysis - why was it failing?
- `faFixType`: One of: EdgeCaseFix, LogicFix, TypeFix, BoundaryFix, InitializationFix, or OtherFix

## Example Output

```json
{
  "fixChanges": [
    {
      "faFunction": "push",
      "faWhatChanged": "Fixed off-by-one in size tracking",
      "faWhyFailed": "Size was incremented before adding element",
      "faFixType": "BoundaryFix"
    }
  ],
  "fixBuildPassed": true,
  "fixCommitMsg": "fix(stack): correct size tracking in push operation",
  "fixBlocker": null
}
```

## Critical Guidelines

1. **Tests are correct** - If a test fails, your impl is wrong
2. **Don't repeat failed fixes** - Check "Fixes Already Tried" above
3. **Track root causes** - Your `faWhyFailed` helps future attempts
4. **Be specific** - Generic fixes don't help diagnose issues
5. **If truly stuck** - Set `fixBlocker` with a clear explanation

## Your Task

Fix the failing tests. The counterexamples and failure messages tell you exactly what's wrong. Make targeted fixes based on the evidence, not guesses.
